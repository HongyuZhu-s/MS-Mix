<div align="center">
<!-- <h1>MS-Mix: Unveiling the Power of Mixup for Multimodal Sentiment Analysis</h1> -->
<h2>MS-Mix: Unveiling the Power of Mixup for Multimodal Sentiment Analysis</a></h2>

<p align="center">
<img src="https://github.com/HongyuZhu-s/MS-Mix/blob/main/Fig/5ffb62f0-398d-430e-90ab-f8a76d46b080.png" width=75% height=75% 
class="center">
</p>

<div align="left">
Although Mixup-based augmentation improves generalization in unimodal tasks, its direct application to MSA introduces critical challenges: random mixing often amplifies label ambiguity and semantic inconsistency due to the lack of emotion-aware mixing mechanisms. To overcome these issues, we propose **MS-Mix**, an adaptive, emotion-sensitive augmentation framework that automatically optimizes sample mixing in multimodal settings.

### ðŸ“¬ If you are interested in my work, you can contact me by email: zhuhongyu@cigit.ac.cn

___
## ðŸ›  Installation
We use the **M-SENA framework** ("https://github.com/thuiar/MMSA") to evaluate MSA models. It is a unified framework for multimodal sentiment analysis. Please install it before proceeding.

*Run `pip install MMSA` in your python virtual environment.*


